# H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG H·ªÜ TH·ªêNG SMOKING DETECTION

## üìö M·ª§C L·ª§C
1. [C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng](#1-c√†i-ƒë·∫∑t-m√¥i-tr∆∞·ªùng)
2. [Training Model](#2-training-model)
3. [Prediction](#3-prediction)
4. [T√πy ch·ªânh Parameters](#4-t√πy-ch·ªânh-parameters)
5. [Troubleshooting](#5-troubleshooting)

---

## 1. C√ÄI ƒê·∫∂T M√îI TR∆Ø·ªúNG

### 1.1. Y√™u c·∫ßu h·ªá th·ªëng

**Minimum:**
- OS: Windows 10/11, Linux, macOS
- Python: 3.8+
- RAM: 8GB
- Storage: 20GB free

**Recommended:**
- Python: 3.9-3.11
- RAM: 16GB
- GPU: NVIDIA v·ªõi CUDA support
- VRAM: 4GB+ (RTX 3050 Ti ho·∫∑c t∆∞∆°ng ƒë∆∞∆°ng)
- Storage: 50GB free

### 1.2. C√†i ƒë·∫∑t Dependencies

```bash
# T·∫°o virtual environment (khuy·∫øn ngh·ªã)
python -m venv venv

# Activate environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Verify CUDA (n·∫øu c√≥ GPU)
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
python -c "import torch; print(f'CUDA version: {torch.version.cuda}')"
```

**requirements.txt:**
```
ultralytics>=8.0.0
torch>=2.0.0
torchvision>=0.15.0
opencv-python>=4.8.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
pyyaml>=6.0
pillow>=10.0.0
```

### 1.3. Ki·ªÉm tra c√†i ƒë·∫∑t

```bash
# Test imports
python -c "from ultralytics import YOLO; print('Ultralytics OK')"
python -c "import cv2; print('OpenCV OK')"
python -c "import torch; print('PyTorch OK')"

# Check GPU
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\"}')"
```

---

## 2. TRAINING MODEL

### 2.1. Chu·∫©n b·ªã Dataset

**C·∫•u tr√∫c th∆∞ m·ª•c:**
```
dataset/smoking_train_image_v6/
‚îú‚îÄ‚îÄ data.yaml
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ labels/
‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ labels/
‚îî‚îÄ‚îÄ test/
    ‚îú‚îÄ‚îÄ images/
    ‚îî‚îÄ‚îÄ labels/
```

**data.yaml:**
```yaml
path: ../dataset/smoking_train_image_v6
train: train/images
val: val/images
test: test/images

nc: 2
names: ['Cigarette', 'Person']
```

### 2.2. Training Commands

**A. Quick Start (Recommended - v8_moderate):**
```bash
cd "smoking_with_yolov8 + aug"
python train_v8_moderate.py
```

**K·∫øt qu·∫£:**
- Training time: ~2.5-3 gi·ªù (50 epochs, RTX 3050 Ti)
- Output: `runs/train/smoking_detection_v8_moderate/`
- Expected: mAP50 ‚â•79%, Recall ‚â•76%

**B. Custom Training:**
```bash
python train.py \
    --data dataset/smoking_train_image_v6/data.yaml \
    --epochs 50 \
    --batch 12 \
    --imgsz 640 \
    --name my_custom_training
```

**C. Continue t·ª´ checkpoint:**
```bash
python train.py --resume runs/train/smoking_detection_v8_moderate/weights/last.pt
```

**D. Transfer learning t·ª´ model kh√°c:**
```bash
python train.py \
    --model runs/train/smoking_detection_v6_optimized/weights/best.pt \
    --data dataset/smoking_train_image_v6/data.yaml \
    --epochs 20 \
    --name fine_tuning
```

### 2.3. Monitor Training

**Real-time monitoring:**
```bash
# TensorBoard (n·∫øu c√†i ƒë·∫∑t)
tensorboard --logdir runs/train

# Ho·∫∑c xem tr·ª±c ti·∫øp trong terminal
# Training s·∫Ω hi·ªÉn th·ªã:
# - Loss (box, cls, dfl)
# - Metrics (Precision, Recall, mAP50, mAP50-95)
# - Learning rate
# - ETA
```

**Xem k·∫øt qu·∫£:**
```bash
# Results CSV
code runs/train/smoking_detection_v8_moderate/results.csv

# Training args
code runs/train/smoking_detection_v8_moderate/args.yaml

# Confusion matrix, F1 curve, PR curve
explorer runs/train/smoking_detection_v8_moderate/
```

### 2.4. Training Parameters chi ti·∫øt

**Basic Settings:**
```python
epochs: 50              # S·ªë epochs (v6: 80, v8: 50)
batch: 12               # Batch size (t√πy VRAM)
imgsz: 640              # Image size
patience: 25            # Early stopping
close_mosaic: 10        # T·∫Øt mosaic cu·ªëi training
```

**Optimizer:**
```python
optimizer: 'AdamW'      # AdamW ho·∫∑c SGD
lr0: 0.013              # Initial learning rate
lrf: 0.0005             # Final LR (fraction of lr0)
cos_lr: True            # Cosine LR scheduler
warmup_epochs: 6        # Warmup epochs
momentum: 0.937
weight_decay: 0.0005
```

**Loss Weights:**
```python
box: 11.0               # Box loss weight
cls: 2.2                # Classification loss
dfl: 2.3                # DFL loss (small objects)
```

**Augmentation:**
```python
scale: 0.55             # Image scaling
copy_paste: 0.4         # Copy-paste augmentation
mixup: 0.22             # Mixup augmentation
translate: 0.15         # Translation
degrees: 12             # Rotation
shear: 2.5              # Shearing
fliplr: 0.5             # Horizontal flip
hsv_h: 0.018            # Hue augmentation
hsv_s: 0.75             # Saturation
hsv_v: 0.45             # Value
```

---

## 3. PREDICTION

### 3.1. Image Prediction

**A. Basic Usage:**
```bash
python predict_image.py --image input_data/images/test.jpg
```

**Output:**
- File: `results/image/{timestamp}_smoking_test.jpg`
- Console: Detection results v·ªõi confidence scores

**B. Batch Processing:**
```bash
# Process all images in folder
python predict_image.py --image input_data/images/

# Output: results/image/{timestamp}_smoking_{filename}.jpg
```

**C. Custom Model:**
```bash
python predict_image.py \
    --model runs/train/my_model/weights/best.pt \
    --image test.jpg \
    --conf 0.25
```

**D. V√≠ d·ª• Output:**
```
Input:  test_smoking.jpg
Output: 20251223_112530_smoking_test_smoking.jpg

Detection Results:
  SMOKING DETECTED ‚úÖ
  - Cigarette (conf: 0.85) near Person head (distance: 45px)
  - Person (conf: 0.92)
```

### 3.2. Video Prediction

**A. Basic Usage (Ch·∫°y ng·∫ßm + Frame extraction):**
```bash
python predict_video.py --video input_data/videos/test.mp4
```

**Output:**
```
results/video/
‚îú‚îÄ‚îÄ 20251223_112939_smoking_test.mp4        # Annotated video
‚îî‚îÄ‚îÄ test_frames/                            # Frames c√≥ smoking
    ‚îú‚îÄ‚îÄ 20251223_112940_123_smoking_frame_0015.jpg
    ‚îú‚îÄ‚îÄ 20251223_112940_456_smoking_frame_0032.jpg
    ‚îî‚îÄ‚îÄ ... (66 frames total)
```

**B. V·ªõi Preview:**
```bash
python predict_video.py --video test.mp4 --show
# Press 'q' ƒë·ªÉ d·ª´ng
```

**C. Ch·ªâ l∆∞u frames, kh√¥ng l∆∞u video:**
```bash
python predict_video.py --video test.mp4 --no-save
```

**D. Kh√¥ng l∆∞u frames:**
```bash
python predict_video.py --video test.mp4 --no-frames
```

**E. Full Options:**
```bash
python predict_video.py \
    --video test.mp4 \
    --model runs/train/custom/weights/best.pt \
    --conf 0.25 \
    --head-dist 100 \
    --upper-dist 200 \
    --show \
    --debug
```

**F. V√≠ d·ª• Output:**
```
üé¨ Processing video: test.mp4
üìä Video info: 1280x720 @ 30fps, 900 frames
üìÅ Frames folder: results/video/test_frames/

============================================================
üéØ K·∫æT QU·∫¢ X·ª¨ L√ù VIDEO
============================================================
  T·ªïng frames: 900
  Frames c√≥ smoking: 135 (15.0%)
  Th·ªùi gian x·ª≠ l√Ω: 16.7s
  FPS trung b√¨nh: 54.0
  üíæ Video ƒë√£ l∆∞u: results/video/20251223_112939_smoking_test.mp4
  üìÅ Frames ƒë√£ l∆∞u: 135 ·∫£nh trong results/video/test_frames/
============================================================
```

### 3.3. Camera Real-time

**A. Basic Usage:**
```bash
python predict_camera.py
```

**Controls:**
- `s`: Save current frame (n·∫øu c√≥ smoking)
- `q`: Quit

**B. Custom Settings:**
```bash
python predict_camera.py \
    --model runs/train/custom/weights/best.pt \
    --conf 0.25 \
    --camera 0 \
    --head-dist 100
```

**C. Auto-save khi ph√°t hi·ªán smoking:**
```bash
# M·∫∑c ƒë·ªãnh: T·ª± ƒë·ªông l∆∞u khi ph√°t hi·ªán smoking
# Output: results/camera/{timestamp}_smoking_camera.jpg
```

**D. V√≠ d·ª• Output:**
```
üé• Camera: 0
üì∏ Auto-save: ON (saves when smoking detected)

Frame 150:
  SMOKING DETECTED ‚úÖ
  - Cigarette (0.87) near Person head (42px)
  üíæ Saved: results/camera/20251223_112530_smoking_camera.jpg

Press 's' to save, 'q' to quit
```

---

## 4. T√ôY CH·ªàNH PARAMETERS

### 4.1. Confidence Threshold

**Default: 0.20** (optimal for best mAP50)

```bash
# TƒÉng conf ‚Üí √çt false positives, nhi·ªÅu false negatives
python predict_image.py --image test.jpg --conf 0.30

# Gi·∫£m conf ‚Üí Nhi·ªÅu detections, nhi·ªÅu false positives
python predict_image.py --image test.jpg --conf 0.15
```

**Khuy·∫øn ngh·ªã:**
- **0.20**: Optimal (best mAP50=66.07%)
- **0.25**: Precision cao h∆°n, √≠t FP
- **0.15**: Recall cao h∆°n, nhi·ªÅu FP

### 4.2. Distance Thresholds

**Head distance (--head-dist):**
- Default: 80px (ƒë·ªÉ v·∫Ω line t·ª´ cigarette ƒë·∫øn head)
- Ch·ªâ ·∫£nh h∆∞·ªüng visualization, kh√¥ng ·∫£nh h∆∞·ªüng detection

**Upper body distance (--upper-dist):**
- Default: 150px (ƒë·ªÉ DETECT smoking)
- Cigarette trong 150px t·ª´ upper body ‚Üí SMOKING ‚úÖ

```bash
# Strict detection (ch·ªâ g·∫ßn ƒë·∫ßu)
python predict_image.py --image test.jpg --head-dist 60 --upper-dist 100

# Loose detection (xa h∆°n)
python predict_image.py --image test.jpg --head-dist 100 --upper-dist 200
```

### 4.3. Strict Face-only Mode

```bash
# Ch·ªâ ph√°t hi·ªán cigarette G·∫¶N M·∫∂T (b·ªè qua n·ª≠a tr√™n th√¢n)
python predict_image.py --image test.jpg --strict-face
```

**Use case:**
- M√¥i tr∆∞·ªùng ƒë√¥ng ng∆∞·ªùi
- Gi·∫£m false positives
- Ch·ªâ quan t√¢m cigarette g·∫ßn mi·ªáng

### 4.4. Debug Mode

```bash
python predict_image.py --image test.jpg --debug

# Output:
# - Detailed detection info
# - Distance calculations
# - Bbox coordinates
# - Confidence scores
```

---

## 5. TROUBLESHOOTING

### 5.1. L·ªói th∆∞·ªùng g·∫∑p

**A. CUDA Out of Memory:**
```
RuntimeError: CUDA out of memory
```

**Gi·∫£i ph√°p:**
```bash
# Gi·∫£m batch size
python train.py --batch 8  # ho·∫∑c 6, 4

# Ho·∫∑c gi·∫£m image size
python train.py --imgsz 512 --batch 12
```

**B. Model kh√¥ng t·ªìn t·∫°i:**
```
‚ùå Model kh√¥ng t·ªìn t·∫°i: runs/train/.../best.pt
```

**Gi·∫£i ph√°p:**
```bash
# Check model path
ls runs/train/smoking_detection_v6_optimized/weights/

# S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
python predict_image.py --model "E:/path/to/best.pt" --image test.jpg
```

**C. Video kh√¥ng m·ªü ƒë∆∞·ª£c:**
```
‚ùå Kh√¥ng th·ªÉ m·ªü video: test.mp4
```

**Gi·∫£i ph√°p:**
```bash
# Check codec
ffmpeg -i test.mp4

# Convert n·∫øu c·∫ßn
ffmpeg -i test.mp4 -c:v libx264 test_converted.mp4
```

**D. Low FPS trong real-time:**
```
FPS: 5-10 (qu√° ch·∫≠m)
```

**Gi·∫£i ph√°p:**
```bash
# Gi·∫£m image size
python predict_camera.py --imgsz 416

# TƒÉng conf threshold
python predict_camera.py --conf 0.30

# S·ª≠ d·ª•ng GPU
python -c "import torch; print(torch.cuda.is_available())"  # Ph·∫£i True
```

### 5.2. Performance Optimization

**A. Training faster:**
```bash
# S·ª≠ d·ª•ng mixed precision (t·ª± ƒë·ªông)
# Gi·∫£m epochs cho testing
python train.py --epochs 20

# TƒÉng workers (CPU cores)
python train.py --workers 12

# S·ª≠ d·ª•ng cache
python train.py --cache ram  # Ho·∫∑c --cache disk
```

**B. Inference faster:**
```python
# Export sang TensorRT (GPU only)
from ultralytics import YOLO
model = YOLO('best.pt')
model.export(format='engine')  # TensorRT

# S·ª≠ d·ª•ng
model = YOLO('best.engine')
results = model.predict('test.jpg')
```

**C. Batch inference:**
```python
from ultralytics import YOLO
import glob

model = YOLO('best.pt')
images = glob.glob('input_data/images/*.jpg')

# Batch processing
results = model.predict(images, batch=16)  # Nhanh h∆°n loop
```

### 5.3. Quality Issues

**A. Nhi·ªÅu False Positives:**
```bash
# TƒÉng confidence threshold
python predict_image.py --conf 0.30

# S·ª≠ d·ª•ng strict face-only mode
python predict_image.py --strict-face

# Retrain v·ªõi better data
```

**B. Nhi·ªÅu False Negatives (missing cigarettes):**
```bash
# Gi·∫£m confidence threshold
python predict_image.py --conf 0.15

# TƒÉng distance threshold
python predict_image.py --upper-dist 200

# Retrain v·ªõi better augmentation
```

**C. K√©m v·ªõi small cigarettes:**
```bash
# S·ª≠ d·ª•ng model l·ªõn h∆°n
python train.py --model yolov8m.pt  # ho·∫∑c yolov8l.pt

# TƒÉng image size
python train.py --imgsz 800

# Adjust loss weights
python train.py --dfl 2.5  # Focus small objects
```

---

## 6. TIPS & BEST PRACTICES

### 6.1. Training Tips

‚úÖ **DO:**
- S·ª≠ d·ª•ng moderate augmentation (nh∆∞ v6, v8)
- Monitor validation metrics (not just training loss)
- Save checkpoints th∆∞·ªùng xuy√™n (`--save-period 10`)
- Validate tr√™n test set sau training
- Document training config trong args.yaml

‚ùå **DON'T:**
- Aggressive augmentation (nh∆∞ v7 - failed)
- Train qu√° l√¢u (risk overfitting)
- Ignore validation loss tƒÉng
- Forget to backup best model

### 6.2. Prediction Tips

‚úÖ **DO:**
- Test v·ªõi nhi·ªÅu conf thresholds
- Verify outputs tr∆∞·ªõc khi deploy
- Use debug mode khi g·∫∑p issue
- Batch process khi c√≥ nhi·ªÅu images

‚ùå **DON'T:**
- Use default conf cho m·ªçi use case
- Deploy without testing
- Ignore false positives/negatives
- Process videos without frame limit check

### 6.3. Dataset Tips

‚úÖ **DO:**
- Balanced classes (50:50 ideal)
- High quality labels
- Diverse scenarios (lighting, angles, distances)
- Regular data cleaning

‚ùå **DON'T:**
- Ignore class imbalance
- Accept poor quality labels
- Collect only easy samples
- Never review/update dataset

---

## 7. ADVANCED USAGE

### 7.1. Python API

```python
from ultralytics import YOLO
import cv2
from smoking_detector import is_smoking_detected
from cigarette_filter import filter_cigarette_detections

# Load model
model = YOLO('runs/train/smoking_detection_v6_optimized/weights/best.pt')

# Predict
image = cv2.imread('test.jpg')
results = model.predict(image, conf=0.20)

# Filter cigarettes
results = filter_cigarette_detections(results)

# Smoking detection
is_smoking, persons, details = is_smoking_detected(results)

print(f"Smoking: {is_smoking}")
print(f"Persons: {persons}")
print(f"Details: {details}")
```

### 7.2. Custom Callback

```python
from ultralytics import YOLO

def on_train_epoch_end(trainer):
    # Custom logic after each epoch
    print(f"Epoch {trainer.epoch}: mAP50 = {trainer.metrics['metrics/mAP50(B)']:.4f}")

model = YOLO('yolov8s.pt')
model.add_callback('on_train_epoch_end', on_train_epoch_end)
model.train(data='data.yaml', epochs=50)
```

### 7.3. Export Models

```python
from ultralytics import YOLO

model = YOLO('best.pt')

# TensorRT (GPU, fastest)
model.export(format='engine')

# ONNX (cross-platform)
model.export(format='onnx')

# CoreML (iOS/macOS)
model.export(format='coreml')

# TFLite (mobile)
model.export(format='tflite')
```

---

**C·∫≠p nh·∫≠t:** December 23, 2025  
**Version:** 1.0  
**Contact:** Support via documentation repository
